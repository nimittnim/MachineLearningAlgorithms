{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from einops import rearrange\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image_patch(img,x,y,z,patch_size):\n",
    "    img_copy = img.clone()\n",
    "    for i in range(patch_size):\n",
    "        for j in range(patch_size):\n",
    "                for k in range(z):\n",
    "                    img_copy[x+i][y+j][k] = torch.nan\n",
    "    return img_copy\n",
    "\n",
    "def mask_image_random(img,patch_size):\n",
    "    img_copy = img.clone()\n",
    "    n = len(img)\n",
    "    m = len(img[0])\n",
    "    random_i = np.random.choice(n*m,patch_size*patch_size,replace=False)\n",
    "    for i in random_i:\n",
    "        for j in range(3):\n",
    "            img_copy[i//n][i%m] = torch.nan\n",
    "    return img_copy\n",
    "\n",
    "def create_mask(t,x,y,patch_size):\n",
    "    mask = torch.full(t.shape,True)\n",
    "    z = t.shape[2]\n",
    "    for i in range(patch_size):\n",
    "        for j in range(patch_size):\n",
    "                for k in range(z):\n",
    "                    mask[x+i][y+j][k] = False\n",
    "    return mask\n",
    "\n",
    "def create_coordinate_map(img):\n",
    "    height, width, num_channels = img.shape\n",
    "    X = torch.empty((img.shape[0],img.shape[1],2))\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            X[i][j][0] = i\n",
    "            X[i][j][1] = j\n",
    "    return X.reshape(-1,2)\n",
    "\n",
    "def stack_itself(t, n):\n",
    "    stacked_t = t.unsqueeze(1).expand(-1, n, -1)\n",
    "    return stacked_t.squeeze()\n",
    "\n",
    "def scale(img):\n",
    "    img_flatted = img.reshape(-1,1)\n",
    "    scaler_X = preprocessing.MinMaxScaler().fit(img_flatted)\n",
    "    img_scaled = scaler_X.transform(img_flatted).reshape(img.shape)\n",
    "    img_scaled = torch.tensor(img_scaled)\n",
    "    img_scaled = img_scaled.float()\n",
    "    return img_scaled\n",
    "\n",
    "def fill_patch(original_img,reconstructed_img_patch,x,y,patch_size):\n",
    "    reconstructed_img = original_img.clone()\n",
    "    for i in range(patch_size):\n",
    "        for j in range(patch_size):\n",
    "                for k in range(3):\n",
    "                    reconstructed_img[x+i][y+j][k] = reconstructed_img_patch[i][j][k]\n",
    "    return reconstructed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torchvision.io.read_image('dog.jpg')\n",
    "img_scaled = scale(img)\n",
    "cropped_img = torchvision.transforms.functional.crop(img_scaled,600,800,300,300)\n",
    "cropped_img = rearrange(cropped_img,'c h w -> h w c')\n",
    "cropped_img = torch.tensor(cropped_img,dtype = torch.float32)\n",
    "original_img = cropped_img.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR + RFF\n",
    "def plot_reconstructed_and_original_image(original_img, masked_img, reconstructed_img, title=\"\"):\n",
    "    \"\"\"\n",
    "    net: torch.nn.Module\n",
    "    X: torch.Tensor of shape (num_samples, 2)\n",
    "    Y: torch.Tensor of shape (num_samples, 3)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1])\n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    ax2 = plt.subplot(gs[2])\n",
    "\n",
    "    ax0.imshow(reconstructed_img)\n",
    "    ax0.set_title(\"Reconstructed Image\")\n",
    "    \n",
    "    ax1.imshow(original_img.cpu())\n",
    "    ax1.set_title(\"Original Image\")\n",
    "\n",
    "    ax2.imshow(masked_img.cpu())\n",
    "    ax2.set_title(\"Masked Image\")\n",
    "\n",
    "    \n",
    "    for a in [ax0, ax1, ax2]:\n",
    "        a.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def create_rff_features(X, num_features, sigma):\n",
    "    from sklearn.kernel_approximation import RBFSampler\n",
    "    rff = RBFSampler(n_components=num_features, gamma=1/(2 * sigma**2))\n",
    "    X = X.cpu().numpy()\n",
    "    X = rff.fit_transform(X)\n",
    "    return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "def train(net, lr, X, Y, max_epochs=2000):\n",
    "    \"\"\"\n",
    "    net: torch.nn.Module\n",
    "    lr: float\n",
    "    X: torch.Tensor of shape (known_pixels, 2) // (x,y)\n",
    "    Y: torch.Tensor of shape (known_pixels, 3) // (r,g,b)\n",
    "    \"\"\"\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    prev_loss = float('inf')  \n",
    "    epsilon = 1e-5\n",
    "    prev_loss = float('inf')\n",
    "    max_epochs = 10000\n",
    "    \n",
    "    for i in range(max_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if abs(prev_loss - loss.item()) < epsilon:\n",
    "            break\n",
    "        prev_loss = loss.item()\n",
    "\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "def image_reconstrunction_linear_rff(original_img,masked_img):\n",
    "    \n",
    "    y = original_img.clone().reshape(-1,3)\n",
    "    X = create_coordinate_map(original_img)\n",
    "    mask = ~torch.isnan(masked_img).reshape(-1,3)\n",
    "    X_train = X[mask[:,0:2]].reshape(-1,2)\n",
    "    y_train = y[mask].reshape(-1,3)\n",
    "\n",
    "    # Without RFF\n",
    "    # net = LinearModel(2,3)\n",
    "    # train(net,0.01,X_train,y_train,1000)\n",
    "    # plot_reconstructed_and_original_image(original_img, net, X, title=\"Reconstructed Image\")\n",
    "\n",
    "    # With RFF\n",
    "    features = 10000\n",
    "    X_rff = create_rff_features(X, features, 0.008)\n",
    "    mask_rff = stack_itself(mask[:,0].unsqueeze(1),features)\n",
    "    X_rff_train = X_rff[mask_rff].reshape(-1,features)\n",
    "    y_rff_train = y[mask].reshape(-1,3)\n",
    "\n",
    "    \n",
    "    netrff = LinearModel(X_rff_train.shape[1], 3)\n",
    "    train(netrff, 0.005, X_rff_train, y_rff_train, 1000)\n",
    "    height, width, num_channels = original_img.shape\n",
    "    netrff.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = netrff(X_rff).reshape(height,width,num_channels)\n",
    "    return reconstructed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(original_img,reconstructed_img):\n",
    "    sum = torch.tensor(0)\n",
    "    for i in range(3):\n",
    "        sum = sum + (nn.functional.mse_loss(original_img[:,:,i],reconstructed_img[:,:,i]))\n",
    "    return sum/3\n",
    "\n",
    "def psnr(original_img,reconstructed_img):\n",
    "    psnr = torch.tensor(0)\n",
    "    for i in range(3):\n",
    "        maxi = torch.max(original_img[:,:,i])\n",
    "        mse = nn.functional.mse_loss(original_img[:,:,i],reconstructed_img[:,:,i])\n",
    "        psnr = psnr + (20*torch.log10(maxi/mse))\n",
    "    return psnr/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a RFF\n",
    "patch_size = 30\n",
    "# x_y_s = [[10,10],[90,150],[140,60]]\n",
    "x_y_s = [[90,150]]\n",
    "reconstructed_images_2 = []\n",
    "\n",
    "for i in range(len(x_y_s)):\n",
    "    print(\"Linear Regression + RFF for 30*30 rectangular patch\")\n",
    "    masked_img = mask_image_patch(original_img,x_y_s[i][0],x_y_s[i][1],3,patch_size)\n",
    "    reconstructed_img = image_reconstrunction_linear_rff(original_img,masked_img)\n",
    "    reconstructed_images_2.append(reconstructed_img)\n",
    "    plot_reconstructed_and_original_image(original_img, masked_img, reconstructed_img, title=\"Reconstructed Image with RFF Features\")\n",
    "    print(\"MSE for reconstruction : \",mse(original_img, reconstructed_img))\n",
    "    print(\"PSNR for reconstruction : \",psnr(original_img, reconstructed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b RFF\n",
    "patch_size = 30\n",
    "titles = [\"Random Missing pixels RFF\"]\n",
    "reconstructed_images_4 = []\n",
    "\n",
    "print(titles[0])\n",
    "masked_img = mask_image_random(original_img, patch_size)\n",
    "reconstructed_img = image_reconstrunction_linear_rff(original_img, masked_img)\n",
    "reconstructed_images_4.append(reconstructed_img)\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(masked_img)\n",
    "axs[1].imshow(reconstructed_img)\n",
    "plt.show()\n",
    "print(\"MSE for reconstruction : \",mse(original_img, reconstructed_img))\n",
    "print(\"PSNR for reconstruction : \",psnr(original_img, reconstructed_img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
