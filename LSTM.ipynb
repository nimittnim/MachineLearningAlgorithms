{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeights(input_size, output_size):\n",
    "    return np.random.uniform(-1, 1, (output_size, input_size)) * np.sqrt(6 / (input_size + output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions \n",
    "def sigmoid(input, derivative = False):\n",
    "    if derivative:\n",
    "        return input * (1 - input)\n",
    "    \n",
    "    return 1 / (1 + np.exp(-input))\n",
    "\n",
    "def tanh(input, derivative = False):\n",
    "    if derivative:\n",
    "        return 1 - input ** 2\n",
    "    \n",
    "    return np.tanh(input)\n",
    "\n",
    "def softmax(input):\n",
    "    return np.exp(input) / np.sum(np.exp(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Short-Term Memory \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        # Hyperparameters\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Forget Gate\n",
    "        self.wf = nn.Parameter(torch.rand(input_size, hidden_size), requires_grad=True)\n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.wi = initWeights(input_size, hidden_size)\n",
    "        self.bi = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Candidate Gate\n",
    "        self.wc = initWeights(input_size, hidden_size)\n",
    "        self.bc = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Output Gate\n",
    "        self.wo = initWeights(input_size, hidden_size)\n",
    "        self.bo = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Final Gate\n",
    "        self.wy = initWeights(hidden_size, output_size)\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    # Reset Network Memory\n",
    "    def reset(self):\n",
    "        self.concat_inputs = {}\n",
    "\n",
    "        self.hidden_states = {-1:np.zeros((self.hidden_size, 1))}\n",
    "        self.cell_states = {-1:np.zeros((self.hidden_size, 1))}\n",
    "\n",
    "        self.activation_outputs = {}\n",
    "        self.candidate_gates = {}\n",
    "        self.output_gates = {}\n",
    "        self.forget_gates = {}\n",
    "        self.input_gates = {}\n",
    "        self.outputs = {}\n",
    "\n",
    "    # Forward Propogation\n",
    "    def forward(self, X_):\n",
    "        outputs = []\n",
    "        self.reset()\n",
    "        for q in range(len(X_)):\n",
    "\n",
    "            self.concat_inputs[q] = np.concatenate((self.hidden_states[q - 1], X_[q].reshape(-1,1)))\n",
    "        \n",
    "            self.forget_gates[q] = sigmoid(np.matmul(self.wf, self.concat_inputs[q]) + self.bf)\n",
    "            self.input_gates[q] = sigmoid(np.matmul(self.wi, self.concat_inputs[q]) + self.bi)\n",
    "            self.candidate_gates[q] = tanh(np.matmul(self.wc, self.concat_inputs[q]) + self.bc)\n",
    "            self.output_gates[q] = sigmoid(np.matmul(self.wo, self.concat_inputs[q]) + self.bo)\n",
    "\n",
    "            self.cell_states[q] = self.forget_gates[q] * self.cell_states[q - 1] + self.input_gates[q] * self.candidate_gates[q]\n",
    "            self.hidden_states[q] = self.output_gates[q] * tanh(self.cell_states[q])\n",
    "\n",
    "            outputs += [np.matmul(self.wy, self.hidden_states[q]) + self.by]\n",
    "\n",
    "        return np.array(outputs)\n",
    "        \n",
    "    # Backward Propogation\n",
    "    def backward(self, errors, X, lr):\n",
    "        d_wf, d_bf = 0, 0\n",
    "        d_wi, d_bi = 0, 0\n",
    "        d_wc, d_bc = 0, 0\n",
    "        d_wo, d_bo = 0, 0\n",
    "        d_wy, d_by = 0, 0\n",
    "\n",
    "\n",
    "        dh_next, dc_next = np.zeros_like(self.hidden_states[0]), np.zeros_like(self.cell_states[0])\n",
    "        for q in reversed(range(len(X))):\n",
    "\n",
    "            error = errors[q]\n",
    "\n",
    "            # Final Gate Weights and Biases Errors\n",
    "            d_wy += np.matmul(error, self.hidden_states[q].T)\n",
    "            d_by += error\n",
    "\n",
    "            # Hidden State Error\n",
    "            d_hs = np.matmul(self.wy.T, error) + dh_next\n",
    "\n",
    "            # Output Gate Weights and Biases Errors\n",
    "            d_o = tanh(self.cell_states[q]) * d_hs * sigmoid(self.output_gates[q], derivative = True)\n",
    "            d_wo += np.matmul(d_o, X[q].T)\n",
    "            d_bo += d_o\n",
    "\n",
    "            # Cell State Error\n",
    "            d_cs = tanh(tanh(self.cell_states[q]), derivative = True) * self.output_gates[q] * d_hs + dc_next\n",
    "\n",
    "            # Forget Gate Weights and Biases Errors\n",
    "            d_f = d_cs * self.cell_states[q - 1] * sigmoid(self.forget_gates[q], derivative = True)\n",
    "            d_wf += np.matmul(d_f, X[q].T)\n",
    "            d_bf += d_f\n",
    "\n",
    "            # Input Gate Weights and Biases Errors\n",
    "            d_i = d_cs * self.candidate_gates[q] * sigmoid(self.input_gates[q], derivative = True)\n",
    "            d_wi += np.matmul(d_i, X[q].T)\n",
    "            d_bi += d_i\n",
    "            \n",
    "            # Candidate Gate Weights and Biases Errors\n",
    "            d_c = d_cs * self.input_gates[q] * tanh(self.candidate_gates[q], derivative = True)\n",
    "            d_wc += np.matmul(d_c, X[q].T)\n",
    "            d_bc += d_c\n",
    "\n",
    "            # Concatenated Input Error (Sum of Error at Each Gate!)\n",
    "            d_z = np.matmul(self.wf.T, d_f) + np.matmul(self.wi.T, d_i) + np.matmul(self.wc.T, d_c) + np.matmul(self.wo.T, d_o)\n",
    "\n",
    "            # Error of Hidden State and Cell State at Next Time Step\n",
    "            dh_next = d_z[:self.hidden_size, :]\n",
    "            dc_next = self.forget_gates[q] * d_cs\n",
    "\n",
    "        for d_ in (d_wf, d_bf, d_wi, d_bi, d_wc, d_bc, d_wo, d_bo, d_wy, d_by):\n",
    "            np.clip(d_, -1, 1, out = d_)\n",
    "\n",
    "        self.wf += d_wf * lr\n",
    "        self.bf += d_bf * lr\n",
    "\n",
    "        self.wi += d_wi * lr\n",
    "        self.bi += d_bi * lr\n",
    "\n",
    "        self.wc += d_wc * lr\n",
    "        self.bc += d_bc * lr\n",
    "\n",
    "        self.wo += d_wo * lr\n",
    "        self.bo += d_bo * lr\n",
    "\n",
    "        self.wy += d_wy * lr\n",
    "        self.by += d_by * lr\n",
    "\n",
    "    # predict \n",
    "    def predict(self,X):\n",
    "        out = []\n",
    "        for i in range(len(X)):\n",
    "            out.append(self.forward(X[i]))\n",
    "        return np.array(out)\n",
    "\n",
    "    # Train\n",
    "    def train(self, X, y, epochs,lr):\n",
    "\n",
    "        y_new = np.hstack((X,y))\n",
    "        y_new = y_new[:,1:]\n",
    "        \n",
    "                \n",
    "        for _ in range(epochs):\n",
    "            for i in range(len(X)):\n",
    "                prediction = self.forward(X[i])\n",
    "                errors = []\n",
    "                for q in range(len(prediction)):\n",
    "                    errors += [y_new[i][q]- prediction[q]]\n",
    "                errors = np.array(errors)\n",
    "                self.backward(errors, self.concat_inputs,lr)\n",
    "            current_loss = np.mean(abs(errors))\n",
    "            print(current_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
