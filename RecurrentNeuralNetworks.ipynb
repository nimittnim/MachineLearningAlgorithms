{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks\n",
    "\n",
    "In these neural networks the output is influenced by previous inputs too, so useful for sequential data. For example, predicting next word in the sentence. Basically, they have loops which feeds back to the same layer.\n",
    "\n",
    "$ h_{t} = W_{hh}x_{t-1} + W_{hx}x_{t}$ \\\n",
    "$ y_{t} = W_{yh}h_{t}$\n",
    "\n",
    "But these Neural Networks are very hard to train because of vanishing and exploding gradient problem. So, we have its updated version LSTM : Long Short Term Memory Networks where we don't consider all the previous inputs but channelize them into short and long channels using Forget Gate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM cell\n",
    "\n",
    "class LSTMcell(nn.Module):\n",
    "\n",
    "    def __init__(self,m,r):\n",
    "        super().__init__()\n",
    "        # percentage long term to remember\n",
    "        self.w_input_1 = nn.Parameter(torch.rand(r,m),requires_grad=True)\n",
    "        self.w_short_1 = nn.Parameter(torch.rand(r,r),requires_grad=True)\n",
    "        self.b_1 = nn.Parameter(torch.rand(r,1),requires_grad=True)\n",
    "        # sigma\n",
    "\n",
    "        # percentage potential memory to remember\n",
    "        self.w_input_2 = nn.Parameter(torch.rand(r,m),requires_grad=True)\n",
    "        self.w_short_2 = nn.Parameter(torch.rand(r,r),requires_grad=True)\n",
    "        self.b_2 = nn.Parameter(torch.rand(r,1),requires_grad=True)\n",
    "        # sigma\n",
    "\n",
    "        # Potential Long term memory for current input\n",
    "        self.w_input_3 = nn.Parameter(torch.rand(r,m),requires_grad=True)\n",
    "        self.w_short_3 = nn.Parameter(torch.rand(r,r),requires_grad=True)\n",
    "        self.b_3 = nn.Parameter(torch.rand(r,1),requires_grad=True)\n",
    "        # tanh\n",
    "\n",
    "        # New short\n",
    "        self.w_input_4 = nn.Parameter(torch.rand(r,m),requires_grad=True)\n",
    "        self.w_short_4 = nn.Parameter(torch.rand(r,r),requires_grad=True)\n",
    "        self.b_4 = nn.Parameter(torch.rand(r,1),requires_grad=True)\n",
    "        # sigmoid\n",
    "        self.parameters = [self.w_input_1,self.w_input_2,self.w_input_3,self.w_input_4,\n",
    "                           self.w_short_1,self.w_short_2,self.w_short_3,self.w_short_4,\n",
    "                           self.b_1,self.b_2,self.b_3,self.b_4]\n",
    "\n",
    "\n",
    "    def forward(self, input, short, long):\n",
    "        # percentage long term to remember\n",
    "        \n",
    "        o1 = torch.matmul(self.w_input_1, input)\n",
    "        o2 = torch.matmul(self.w_short_1, short)\n",
    "        o3 = torch.mul(long,torch.sigmoid(o1+o2 + self.b_1))\n",
    "\n",
    "        # percentage potential memory to remember\n",
    "        o4 = torch.matmul(self.w_input_2, input)\n",
    "        o5 = torch.matmul(self.w_short_2, short) \n",
    "        o6 = torch.sigmoid(o4+o5 + self.b_2)\n",
    "\n",
    "        # Potential Long term memory for current input\n",
    "        o7 = torch.matmul(self.w_input_3, input)\n",
    "        o8 = torch.matmul(self.w_short_3, short)\n",
    "        o9 = torch.tanh(o7+o8+ self.b_3) \n",
    "\n",
    "        newLong = o3 + torch.mul(o6,o9)\n",
    "        \n",
    "\n",
    "        # new short\n",
    "        o10 = torch.matmul(self.w_input_4, input)\n",
    "        o11 = torch.matmul(self.w_short_4, short)\n",
    "        o12 = torch.sigmoid(o11+o10 + self.b_4)\n",
    "        \n",
    "        newShort = torch.mul(o12,(torch.tanh(newLong)))\n",
    "        \n",
    "        return newShort,newLong\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.ms = []\n",
    "        self.rs = []\n",
    "        self.parameters = []\n",
    "        self.loss_function = nn.MSELoss()\n",
    "    \n",
    "    def add_layer(self,m,r,n): \n",
    "        # m : Input dimension \n",
    "        # n : number of cells in the layer \n",
    "        # r : output dimension\n",
    "        self.layers.append([])  \n",
    "        self.ms.append(m)\n",
    "        self.rs.append(r)   \n",
    "        for i in range(n):\n",
    "            newcell = LSTMcell(m,r)\n",
    "            self.layers[-1].append(newcell)\n",
    "            # self.parameters.append(newcell.parameters)\n",
    "            for param in newcell.parameters:\n",
    "                self.parameters.append(param)\n",
    "                \n",
    "        # self.parameters.append(newcell.w_input_1)\n",
    "        # self.parameters.append(nn.Parameter(newcell.w_input_1))\n",
    "\n",
    "    def out(self, input):\n",
    "        l = len(self.layers)\n",
    "        n = len(self.layers[0])\n",
    "\n",
    "        shorts = []\n",
    "        longs = []\n",
    "\n",
    "        current_input = input[0].unsqueeze(1)\n",
    "        shorts.append([])\n",
    "        longs.append([])\n",
    "        short_, long_ = torch.zeros(self.rs[0],1),torch.zeros(self.rs[0],1)\n",
    "\n",
    "        for k in range(len(self.layers[0])):\n",
    "            short,long = self.layers[0][k](current_input,short_,long_)\n",
    "            shorts[-1].append(short)\n",
    "            longs[-1].append(long)\n",
    "        for j in range(1,l):\n",
    "            short_, long_ = torch.zeros(self.rs[j],1),torch.zeros(self.rs[j],1)\n",
    "            shorts.append([])\n",
    "            longs.append([])\n",
    "            for k in range(len(self.layers[j])):\n",
    "                short,long = self.layers[j][k](shorts[j-1][k],short_,long_)\n",
    "                shorts[-1].append(short)\n",
    "                longs[-1].append(long)\n",
    "\n",
    "        for i in range(1,len(input)):\n",
    "            current_input = input[i].unsqueeze(1)\n",
    "            for k in range(len(self.layers[0])):\n",
    "                    shorts[0][k],longs[0][k] = self.layers[0][k](current_input,shorts[0][k],longs[0][k])\n",
    "            for j in range(1,l):\n",
    "                shorts.append([])\n",
    "                longs.append([])\n",
    "                for k in range(len(self.layers[j])):\n",
    "                    shorts[j][k],longs[j][k] = self.layers[j][k](shorts[j-1][k],shorts[j][k],longs[j][k])\n",
    "        return shorts[l-1]\n",
    "    \n",
    "    def forward(self,X):\n",
    "        out = []\n",
    "        for i in range(len(X)):\n",
    "            out.append(self.out(X[i]))\n",
    "        return torch.tensor(out,requires_grad=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lst,X,y,max_epochs):\n",
    "    optimizer = optim.Adam(lst.parameters,10)\n",
    "    for i in range(max_epochs):\n",
    "        out = lst(X)\n",
    "        loss = lst.loss_function(out,y)\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0,0.5,0.25,1],[1,0.5,0.25,1]],dtype = torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor([0,1],dtype = torch.float32).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = LSTM()\n",
    "lst.add_layer(1,2,1)\n",
    "lst.add_layer(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2759, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(lst,X,y,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.1543],\n",
       "         [0.8012]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.7673],\n",
       "         [0.4382]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2858],\n",
       "         [0.8848]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2428],\n",
       "         [0.8932]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.7087, 0.3757],\n",
       "         [0.0078, 0.3358]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2180, 0.4823],\n",
       "         [0.6483, 0.1886]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.0409, 0.5645],\n",
       "         [0.5733, 0.5066]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2276, 0.3786],\n",
       "         [0.0839, 0.3538]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.3033],\n",
       "         [0.2468]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9270],\n",
       "         [0.4049]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5442],\n",
       "         [0.1918]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9006],\n",
       "         [0.0453]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.0885, 0.5179]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.3851, 0.7340]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.8352, 0.6862]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.7438, 0.8749]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9915]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5842]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9451]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.3789]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.9219]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.6513]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.2390]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.3663]], requires_grad=True)]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = LSTMcell(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0]],dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
