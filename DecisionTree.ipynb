{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import xlogy\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ifreal(X: pd.Series) -> bool:\n",
    "\n",
    "    return X.dtype.name != 'category'\n",
    "\n",
    "\n",
    "def entropy(Y: pd.Series) -> float:\n",
    "\n",
    "    vals = Y.value_counts(normalize=True)\n",
    "    return -np.sum(xlogy(vals, vals))\n",
    "\n",
    "\n",
    "def gini_index(Y: pd.Series) -> float:\n",
    "\n",
    "    vals = Y.value_counts(normalize=True)\n",
    "    return 1 - np.sum(np.square(vals))\n",
    "\n",
    "\n",
    "def information_gain(Y: pd.Series, attr: pd.Series, criterion) -> float:\n",
    "\n",
    "    criterion_func_map = {\n",
    "        'information_gain': entropy,\n",
    "        'gini_index': gini_index,\n",
    "        'mse': np.var\n",
    "    }\n",
    "\n",
    "    func = criterion_func_map[criterion]\n",
    "    value_before = func(Y)\n",
    "    split_value = None\n",
    "    if check_ifreal(attr):\n",
    "        split_value = opt_split_value(pd.DataFrame(attr), Y, attr.name)\n",
    "        value_after = Y.groupby(attr <= split_value).apply(lambda group: len(group) / len(Y) * func(group)).sum()\n",
    "    else:\n",
    "        value_after = Y.groupby(attr).apply(lambda group: len(group) / len(Y) * func(group)).sum()\n",
    "\n",
    "    return (value_before - value_after, split_value)\n",
    "\n",
    "\n",
    "def opt_split_attribute(X: pd.DataFrame, y: pd.Series, criterion, features: pd.Series):\n",
    "\n",
    "    y = y if check_ifreal(y) else y.cat.codes\n",
    "    scores = {feature: information_gain(y, X[feature], criterion) for feature in features}\n",
    "\n",
    "    key = max(scores, key=lambda value: scores[value][0])\n",
    "    return key, scores[key][0], scores[key][1]\n",
    "\n",
    "\n",
    "def real_variance(X: pd.DataFrame, y: pd.Series, value: np.float64 , attribute):\n",
    "\n",
    "    mask = (X[attribute] <= value)\n",
    "    var_left = np.var(y[mask]) * len(y[mask])\n",
    "    var_right = np.var(y[~mask]) * len(y[~mask])\n",
    "    return var_left + var_right\n",
    "\n",
    "\n",
    "def opt_split_value(X: pd.DataFrame, y: pd.Series, attribute):\n",
    "\n",
    "    X = X.sort_values(by=[attribute])\n",
    "    check_values = [(X[attribute].iloc[i] + X[attribute].iloc[i+1]) / 2 for i in range(X.shape[0]-1)]\n",
    "\n",
    "    y = y if check_ifreal(y) else y.cat.codes\n",
    "    min_var = float('inf')\n",
    "    optimal_value = None\n",
    "\n",
    "    for value in check_values:\n",
    "        var = real_variance(X, y, value, attribute)\n",
    "        if var < min_var:\n",
    "            min_var = var\n",
    "            optimal_value = value\n",
    "\n",
    "    return optimal_value\n",
    "\n",
    "\n",
    "def split_data(X: pd.DataFrame, y: pd.Series, attribute, value=None):\n",
    "\n",
    "    if not check_ifreal(X[attribute]):\n",
    "        unique_values = np.array(X[attribute].unique())\n",
    "        return [(X[X[attribute] == val], y[X[attribute] == val]) for val in unique_values], unique_values\n",
    "    else:\n",
    "        mask = (X[attribute] <= value)\n",
    "        return [(X[mask], y[mask]), (X[~mask], y[~mask])], value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, attribute=None, depth=None, impurity=None, split_values=None, value=None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.split_values = split_values\n",
    "        self.impurity = impurity\n",
    "        self.depth = depth\n",
    "        self.subnodes = {}\n",
    "        self.is_leaf = False if value is None else True\n",
    "\n",
    "@dataclass\n",
    "class DecisionTree:\n",
    "\n",
    "    criterion: Literal[\"information_gain\", \"gini_index\"]\n",
    "    max_depth: int  \n",
    "    def __init__(self, criterion, max_depth=5):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.node = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, depth=0) -> None:\n",
    "\n",
    "        attr, impurity, split_value = opt_split_attribute(X, y, self.criterion, X.columns.tolist())\n",
    "        if depth >= self.max_depth or X.shape[0] == 0 or y.nunique() == 1:\n",
    "            self.node = Node(depth=depth, impurity=impurity, value=y.median() if check_ifreal(y) else y.mode()[0])\n",
    "            return\n",
    "\n",
    "\n",
    "        splitted_data, values = split_data(X, y, attr, split_value)\n",
    "\n",
    "        self.node = Node(attr, depth, impurity, values)\n",
    "        if check_ifreal(X[attr]):\n",
    "            for value, data in zip([True, False], splitted_data):\n",
    "                subtree = DecisionTree(self.criterion, self.max_depth)\n",
    "                subtree.fit(data[0], data[1], depth + 1)\n",
    "                self.node.subnodes[value] = subtree\n",
    "        else:\n",
    "            for value, data in zip(values, splitted_data):\n",
    "                subtree = DecisionTree(self.criterion, self.max_depth)\n",
    "                subtree.fit(data[0], data[1], depth + 1)\n",
    "                self.node.subnodes[value] = subtree\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "        def traverse_tree(x, node):\n",
    "            if node.is_leaf:\n",
    "                return node.value\n",
    "            attr = node.attribute\n",
    "            split_values = node.split_values\n",
    "            value = x[attr] <= split_values if check_ifreal(x) else x[attr]\n",
    "            if value in node.subnodes:\n",
    "                return traverse_tree(x, node.subnodes[value].node)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Value {value} of {attr} not found in node {node}\")\n",
    "\n",
    "        predictions = X.apply(traverse_tree, axis=1, args=(self.node,))\n",
    "        return predictions\n",
    "\n",
    "    def plot(self, depth=0) -> None:\n",
    "        \"\"\"\n",
    "        Function to plot the tree\n",
    "\n",
    "        Output Example:\n",
    "        ?(X1 > 4)\n",
    "            Y: ?(X2 > 7)\n",
    "                Y: Class A\n",
    "                N: Class B\n",
    "            N: Class C\n",
    "        Where Y => Yes and N => No\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.node\n",
    "\n",
    "        if node.is_leaf:\n",
    "            # If the node is a leaf node\n",
    "            print(f\"Class {node.value}\")\n",
    "        else:\n",
    "            # If the node is an internal node\n",
    "            attribute = node.attribute\n",
    "            split_values = node.split_values\n",
    "            if isinstance(split_values, np.ndarray):\n",
    "                # Discrete input\n",
    "                for value, subnode in node.subnodes.items():\n",
    "                    endline = '' if subnode.node.is_leaf else '\\n'\n",
    "                    print(f\"{' ' * depth * 4}?(column {attribute} == {value}): \", end=endline)\n",
    "                    subnode.plot(depth + 1)\n",
    "            else:\n",
    "                # Real input\n",
    "                print(f\"?({attribute} <= {split_values})\")\n",
    "                for value, subnode in node.subnodes.items():\n",
    "                    print(f\"{' ' * depth * 4}{value}: \", end=\"\")\n",
    "                    subnode.plot(depth + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
